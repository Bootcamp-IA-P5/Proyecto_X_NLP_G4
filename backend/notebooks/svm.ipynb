{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2842971",
   "metadata": {},
   "source": [
    "# SVM model for toxic YouTube comments\n",
    "\n",
    "En este notebook entrenamos un modelo de **SVM (LinearSVC)** para detectar\n",
    "comentarios de odio/toxicidad en YouTube.\n",
    "\n",
    "Objetivos:\n",
    "\n",
    "- Cargar el dataset **preprocesado** (texto limpio/lematizado + etiquetas).\n",
    "- Definir columna de texto y columna objetivo (`IsToxic` u otra).\n",
    "- Vectorizar el texto con **TF-IDF** (unigramas y bigramas).\n",
    "- Entrenar un modelo **LinearSVC** con `class_weight=\"balanced\"`.\n",
    "- Evaluar el modelo (accuracy, precision, recall, f1, ROC-AUC).\n",
    "- Guardar el modelo entrenado como **`.pkl`** en `models/`.\n",
    "- Guardar las métricas en un **`.json`** en `results/` con el formato acordado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad173146",
   "metadata": {},
   "source": [
    "## 1. Imports y configuración\n",
    "\n",
    "Importamos todas las librerías necesarias para:\n",
    "\n",
    "- Carga de datos y manejo de rutas (`pandas`, `pathlib`).\n",
    "- Modelado (`scikit-learn`).\n",
    "- Guardado de modelo (`joblib`) y métricas (`json`).\n",
    "- Medición de tiempo y timestamp (`datetime`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c20cae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "import joblib\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4419f874",
   "metadata": {},
   "source": [
    "## 2. Carga del dataset preprocesado\n",
    "\n",
    "Cargamos el CSV **ya preprocesado** generado en el notebook de preprocessing\n",
    "(`preprocessing_eda.ipynb` o similar).\n",
    "\n",
    "- Ajusta la ruta `PREPROCESSED_PATH` según el nombre real de tu fichero.\n",
    "- Este CSV debería contener:\n",
    "  - Una columna de texto procesado (`text_processed` o similar).\n",
    "  - La columna objetivo (`IsToxic` u otra).\n",
    "  - Opcionalmente, features numéricos diseñados a mano (longitud, mayúsculas, etc.).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fb47be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape del dataset preprocesado: (997, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CommentId</th>\n",
       "      <th>VideoId</th>\n",
       "      <th>Text</th>\n",
       "      <th>IsToxic</th>\n",
       "      <th>IsAbusive</th>\n",
       "      <th>IsThreat</th>\n",
       "      <th>IsProvocative</th>\n",
       "      <th>IsObscene</th>\n",
       "      <th>IsHatespeech</th>\n",
       "      <th>IsRacist</th>\n",
       "      <th>IsReligiousHate</th>\n",
       "      <th>text_basic</th>\n",
       "      <th>text_classic</th>\n",
       "      <th>text_len_classic</th>\n",
       "      <th>word_count_classic</th>\n",
       "      <th>uppercase_ratio</th>\n",
       "      <th>exclamation_count</th>\n",
       "      <th>hate_words_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ugg2KwwX0V8-aXgCoAEC</td>\n",
       "      <td>04kJtp6pVXI</td>\n",
       "      <td>If only people would just take a step back and...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>If only people would just take a step back and...</td>\n",
       "      <td>people would take step back make case wasnt an...</td>\n",
       "      <td>850</td>\n",
       "      <td>129</td>\n",
       "      <td>0.014121</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ugg2s5AzSPioEXgCoAEC</td>\n",
       "      <td>04kJtp6pVXI</td>\n",
       "      <td>Law enforcement is not trained to shoot to app...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Law enforcement is not trained to shoot to app...</td>\n",
       "      <td>law enforcement trained shoot apprehend traine...</td>\n",
       "      <td>90</td>\n",
       "      <td>13</td>\n",
       "      <td>0.036232</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ugg3dWTOxryFfHgCoAEC</td>\n",
       "      <td>04kJtp6pVXI</td>\n",
       "      <td>\\r\\nDont you reckon them 'black lives matter' ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Dont you reckon them 'black lives matter' bann...</td>\n",
       "      <td>dont reckon black life matter banner held whit...</td>\n",
       "      <td>252</td>\n",
       "      <td>40</td>\n",
       "      <td>0.002375</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ugg7Gd006w1MPngCoAEC</td>\n",
       "      <td>04kJtp6pVXI</td>\n",
       "      <td>There are a very large number of people who do...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>There are a very large number of people who do...</td>\n",
       "      <td>large number people like police officer called...</td>\n",
       "      <td>339</td>\n",
       "      <td>49</td>\n",
       "      <td>0.015464</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ugg8FfTbbNF8IngCoAEC</td>\n",
       "      <td>04kJtp6pVXI</td>\n",
       "      <td>The Arab dude is absolutely right, he should h...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>The Arab dude is absolutely right, he should h...</td>\n",
       "      <td>arab dude absolutely right shot extra time sho...</td>\n",
       "      <td>138</td>\n",
       "      <td>23</td>\n",
       "      <td>0.020576</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              CommentId      VideoId  \\\n",
       "0  Ugg2KwwX0V8-aXgCoAEC  04kJtp6pVXI   \n",
       "1  Ugg2s5AzSPioEXgCoAEC  04kJtp6pVXI   \n",
       "2  Ugg3dWTOxryFfHgCoAEC  04kJtp6pVXI   \n",
       "3  Ugg7Gd006w1MPngCoAEC  04kJtp6pVXI   \n",
       "4  Ugg8FfTbbNF8IngCoAEC  04kJtp6pVXI   \n",
       "\n",
       "                                                Text  IsToxic  IsAbusive  \\\n",
       "0  If only people would just take a step back and...    False      False   \n",
       "1  Law enforcement is not trained to shoot to app...     True       True   \n",
       "2  \\r\\nDont you reckon them 'black lives matter' ...     True       True   \n",
       "3  There are a very large number of people who do...    False      False   \n",
       "4  The Arab dude is absolutely right, he should h...    False      False   \n",
       "\n",
       "   IsThreat  IsProvocative  IsObscene  IsHatespeech  IsRacist  \\\n",
       "0     False          False      False         False     False   \n",
       "1     False          False      False         False     False   \n",
       "2     False          False       True         False     False   \n",
       "3     False          False      False         False     False   \n",
       "4     False          False      False         False     False   \n",
       "\n",
       "   IsReligiousHate                                         text_basic  \\\n",
       "0            False  If only people would just take a step back and...   \n",
       "1            False  Law enforcement is not trained to shoot to app...   \n",
       "2            False  Dont you reckon them 'black lives matter' bann...   \n",
       "3            False  There are a very large number of people who do...   \n",
       "4            False  The Arab dude is absolutely right, he should h...   \n",
       "\n",
       "                                        text_classic  text_len_classic  \\\n",
       "0  people would take step back make case wasnt an...               850   \n",
       "1  law enforcement trained shoot apprehend traine...                90   \n",
       "2  dont reckon black life matter banner held whit...               252   \n",
       "3  large number people like police officer called...               339   \n",
       "4  arab dude absolutely right shot extra time sho...               138   \n",
       "\n",
       "   word_count_classic  uppercase_ratio  exclamation_count  hate_words_count  \n",
       "0                 129         0.014121                  0                 2  \n",
       "1                  13         0.036232                  0                 3  \n",
       "2                  40         0.002375                  0                 1  \n",
       "3                  49         0.015464                  0                 0  \n",
       "4                  23         0.020576                  0                 1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ajusta esta ruta al nombre del CSV que generaste en preprocessing\n",
    "PREPROCESSED_PATH = Path(\"../../data/preprocessing_data/youtoxic_english_1000_clean.csv\")\n",
    "\n",
    "df = pd.read_csv(PREPROCESSED_PATH)\n",
    "\n",
    "print(\"Shape del dataset preprocesado:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6546a071",
   "metadata": {},
   "source": [
    "## 3. Definición de columnas de texto, target y features numéricas\n",
    "\n",
    "Nuestro dataset preprocesado incluye:\n",
    "\n",
    "- `text_classic`: texto preprocesado pensado para **modelos clásicos**\n",
    "  (TF-IDF, Naive Bayes, Regresión Logística, SVM, etc.).\n",
    "- `text_basic`: texto más \"ligero\" para modelos **modernos** (embeddings, transformers, etc.).\n",
    "- 5 features numéricas de apoyo:\n",
    "  - `text_len_classic`\n",
    "  - `word_count_classic`\n",
    "  - `uppercase_ratio`\n",
    "  - `exclamation_count`\n",
    "  - `hate_words_count`\n",
    "\n",
    "Como SVM es un modelo clásico, en este notebook usaremos **`text_classic`**\n",
    "junto con esas 5 features numéricas.\n",
    "\n",
    "También definimos la columna objetivo (`IsToxic`), que representa la tarea de\n",
    "clasificación binaria (tóxico / no tóxico).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c843fe4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto: False\n",
      "Target: True\n",
      "Features numéricas presentes: []\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'text_processed'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yeder\\Documents\\Factoria F5 Bootcamp IA\\Proyecto_X_NLP_G4\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'text_processed'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Eliminamos filas con target nulo por seguridad\u001b[39;00m\n\u001b[32m     21\u001b[39m df = df.dropna(subset=[TARGET_COL]).reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m X_text = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mTEXT_COL\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     24\u001b[39m y = df[TARGET_COL].astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m     26\u001b[39m n_samples = df.shape[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yeder\\Documents\\Factoria F5 Bootcamp IA\\Proyecto_X_NLP_G4\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yeder\\Documents\\Factoria F5 Bootcamp IA\\Proyecto_X_NLP_G4\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'text_processed'"
     ]
    }
   ],
   "source": [
    "# Texto para modelos clásicos\n",
    "TEXT_COL = \"text_classic\"\n",
    "\n",
    "# Columna objetivo binaria (ajusta si usáis otra, por ejemplo IsAnyToxic)\n",
    "TARGET_COL = \"IsToxic\"\n",
    "\n",
    "# Features numéricas ya creadas en el preprocessing\n",
    "NUMERIC_FEATURES = [\n",
    "    \"text_len_classic\",\n",
    "    \"word_count_classic\",\n",
    "    \"uppercase_ratio\",\n",
    "    \"exclamation_count\",\n",
    "    \"hate_words_count\",\n",
    "]\n",
    "\n",
    "print(\"Comprobación de columnas:\")\n",
    "print(\"  TEXT_COL existe      :\", TEXT_COL in df.columns)\n",
    "print(\"  TARGET_COL existe    :\", TARGET_COL in df.columns)\n",
    "print(\"  Numeric features OK  :\", [c for c in NUMERIC_FEATURES if c in df.columns])\n",
    "\n",
    "# Eliminamos filas con target nulo por seguridad\n",
    "df = df.dropna(subset=[TARGET_COL]).reset_index(drop=True)\n",
    "\n",
    "X_text = df[TEXT_COL]\n",
    "y = df[TARGET_COL].astype(int)\n",
    "\n",
    "n_samples = df.shape[0]\n",
    "print(f\"\\nNúmero de muestras utilizadas: {n_samples}\")\n",
    "print(\"\\nDistribución de la clase objetivo:\")\n",
    "print(y.value_counts(normalize=True).sort_index())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
