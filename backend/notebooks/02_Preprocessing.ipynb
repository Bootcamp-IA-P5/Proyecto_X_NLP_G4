{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcd10dcf",
   "metadata": {},
   "source": [
    "# 02 - Preprocessing YouTube Toxic Comments\n",
    "\n",
    "En este notebook realizamos el **preprocesamiento** de los comentarios de YouTube\n",
    "para dejar un CSV limpio y listo para el modelado posterior.\n",
    "\n",
    "Objetivos:\n",
    "\n",
    "- Cargar el dataset original usado en `01_EDA.ipynb`.\n",
    "- Definir la columna de texto y las columnas de etiquetas.\n",
    "- Crear una etiqueta binaria agregada (`IsAnyToxic`).\n",
    "- Limpiar el texto con expresiones regulares.\n",
    "- Tokenizar, eliminar *stopwords* y lematizar usando spaCy.\n",
    "- Generar una columna de texto final `text_processed`.\n",
    "- Guardar un CSV preprocesado para ser usado en `03_Modeling.ipynb`,\n",
    "  donde se generarán los PKL (vectorizador, modelo, etc.).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211c80ac",
   "metadata": {},
   "source": [
    "## 1. Imports y configuración\n",
    "\n",
    "Importamos las librerías necesarias:\n",
    "\n",
    "- `pandas`, `numpy`: manejo de datos.\n",
    "- `re`: expresiones regulares para limpieza de texto.\n",
    "- `spacy`: tokenización y lematización.\n",
    "- `pathlib`: manejo de rutas.\n",
    "\n",
    "> **Nota:** Antes de ejecutar este notebook puede ser necesario instalar\n",
    "> el modelo de spaCy con:  \n",
    "> `python -m spacy download en_core_web_sm`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "130683f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import spacy\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ba40c2",
   "metadata": {},
   "source": [
    "## 2. Carga de datos\n",
    "\n",
    "Cargamos el dataset original que ya hemos explorado en el notebook de EDA.\n",
    "\n",
    "> Ajusta `DATA_PATH` a la ruta real donde tengas tu CSV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c91b58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del DataFrame (filas, columnas): (1000, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CommentId</th>\n",
       "      <th>VideoId</th>\n",
       "      <th>Text</th>\n",
       "      <th>IsToxic</th>\n",
       "      <th>IsAbusive</th>\n",
       "      <th>IsThreat</th>\n",
       "      <th>IsProvocative</th>\n",
       "      <th>IsObscene</th>\n",
       "      <th>IsHatespeech</th>\n",
       "      <th>IsRacist</th>\n",
       "      <th>IsNationalist</th>\n",
       "      <th>IsSexist</th>\n",
       "      <th>IsHomophobic</th>\n",
       "      <th>IsReligiousHate</th>\n",
       "      <th>IsRadicalism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ugg2KwwX0V8-aXgCoAEC</td>\n",
       "      <td>04kJtp6pVXI</td>\n",
       "      <td>If only people would just take a step back and...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ugg2s5AzSPioEXgCoAEC</td>\n",
       "      <td>04kJtp6pVXI</td>\n",
       "      <td>Law enforcement is not trained to shoot to app...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ugg3dWTOxryFfHgCoAEC</td>\n",
       "      <td>04kJtp6pVXI</td>\n",
       "      <td>\\r\\nDont you reckon them 'black lives matter' ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ugg7Gd006w1MPngCoAEC</td>\n",
       "      <td>04kJtp6pVXI</td>\n",
       "      <td>There are a very large number of people who do...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ugg8FfTbbNF8IngCoAEC</td>\n",
       "      <td>04kJtp6pVXI</td>\n",
       "      <td>The Arab dude is absolutely right, he should h...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              CommentId      VideoId  \\\n",
       "0  Ugg2KwwX0V8-aXgCoAEC  04kJtp6pVXI   \n",
       "1  Ugg2s5AzSPioEXgCoAEC  04kJtp6pVXI   \n",
       "2  Ugg3dWTOxryFfHgCoAEC  04kJtp6pVXI   \n",
       "3  Ugg7Gd006w1MPngCoAEC  04kJtp6pVXI   \n",
       "4  Ugg8FfTbbNF8IngCoAEC  04kJtp6pVXI   \n",
       "\n",
       "                                                Text  IsToxic  IsAbusive  \\\n",
       "0  If only people would just take a step back and...    False      False   \n",
       "1  Law enforcement is not trained to shoot to app...     True       True   \n",
       "2  \\r\\nDont you reckon them 'black lives matter' ...     True       True   \n",
       "3  There are a very large number of people who do...    False      False   \n",
       "4  The Arab dude is absolutely right, he should h...    False      False   \n",
       "\n",
       "   IsThreat  IsProvocative  IsObscene  IsHatespeech  IsRacist  IsNationalist  \\\n",
       "0     False          False      False         False     False          False   \n",
       "1     False          False      False         False     False          False   \n",
       "2     False          False       True         False     False          False   \n",
       "3     False          False      False         False     False          False   \n",
       "4     False          False      False         False     False          False   \n",
       "\n",
       "   IsSexist  IsHomophobic  IsReligiousHate  IsRadicalism  \n",
       "0     False         False            False         False  \n",
       "1     False         False            False         False  \n",
       "2     False         False            False         False  \n",
       "3     False         False            False         False  \n",
       "4     False         False            False         False  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ruta al CSV original (ajústala según tu estructura de proyecto)\n",
    "DATA_PATH = Path(\"../../data/youtoxic_english_1000.csv\")\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(\"Tamaño del DataFrame (filas, columnas):\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace18a13",
   "metadata": {},
   "source": [
    "## 3. Definición de columnas de interés\n",
    "\n",
    "Definimos:\n",
    "\n",
    "- Columnas de ID (si existen) → `CommentId`, `VideoId` (ajusta si tu dataset difiere).\n",
    "- Columna de texto → `Text`.\n",
    "- Columnas de etiquetas → todas las columnas que empiecen por `\"Is\"`.\n",
    "- Columna binaria agregada `IsAnyToxic` → 1 si alguna etiqueta de toxicidad es verdadera.\n",
    "\n",
    "Esto nos permitirá:\n",
    "\n",
    "- Trabajar en modo **binario** (tóxico vs no tóxico).\n",
    "- O escalar a clasificación **multi-etiqueta** más adelante.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9538d7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todas las columnas del dataset:\n",
      "['CommentId', 'VideoId', 'Text', 'IsToxic', 'IsAbusive', 'IsThreat', 'IsProvocative', 'IsObscene', 'IsHatespeech', 'IsRacist', 'IsNationalist', 'IsSexist', 'IsHomophobic', 'IsReligiousHate', 'IsRadicalism']\n",
      "\n",
      "Columnas de ID: ['CommentId', 'VideoId']\n",
      "Columna de texto: Text\n",
      "Columnas de etiquetas: ['IsToxic', 'IsAbusive', 'IsThreat', 'IsProvocative', 'IsObscene', 'IsHatespeech', 'IsRacist', 'IsNationalist', 'IsSexist', 'IsHomophobic', 'IsReligiousHate', 'IsRadicalism']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IsAnyToxic\n",
       "0    0.538\n",
       "1    0.462\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_columns = df.columns.tolist()\n",
    "print(\"Todas las columnas del dataset:\")\n",
    "print(all_columns)\n",
    "\n",
    "# Ajusta estas columnas si en tu dataset tienen otros nombres\n",
    "id_cols = [col for col in [\"CommentId\", \"VideoId\"] if col in df.columns]\n",
    "text_col = \"Text\"\n",
    "\n",
    "# Todas las columnas que empiezan por \"Is\" las consideramos etiquetas\n",
    "label_cols = [c for c in df.columns if c.startswith(\"Is\")]\n",
    "\n",
    "print(\"\\nColumnas de ID:\", id_cols)\n",
    "print(\"Columna de texto:\", text_col)\n",
    "print(\"Columnas de etiquetas:\", label_cols)\n",
    "\n",
    "# Columna binaria agregada\n",
    "df[\"IsAnyToxic\"] = df[label_cols].any(axis=1).astype(int)\n",
    "\n",
    "df[\"IsAnyToxic\"].value_counts(normalize=True).sort_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4b1a30",
   "metadata": {},
   "source": [
    "## 4. Manejo de valores nulos\n",
    "\n",
    "Revisamos:\n",
    "\n",
    "- Si hay textos nulos en `Text`.\n",
    "- Si hay etiquetas nulas.\n",
    "\n",
    "Acciones:\n",
    "\n",
    "- Rellenar textos nulos con cadena vacía (`\"\"`) para evitar errores de procesamiento.\n",
    "- (Opcional) Eliminar filas completamente sin etiquetas, si existiesen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14c4bdd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nulos en texto y etiquetas:\n",
      "\n",
      "Text               0\n",
      "IsToxic            0\n",
      "IsAbusive          0\n",
      "IsThreat           0\n",
      "IsProvocative      0\n",
      "IsObscene          0\n",
      "IsHatespeech       0\n",
      "IsRacist           0\n",
      "IsNationalist      0\n",
      "IsSexist           0\n",
      "IsHomophobic       0\n",
      "IsReligiousHate    0\n",
      "IsRadicalism       0\n",
      "IsAnyToxic         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Nulos en texto y etiquetas:\\n\")\n",
    "print(df[[text_col] + label_cols + [\"IsAnyToxic\"]].isna().sum())\n",
    "\n",
    "# Rellenar textos nulos con cadena vacía\n",
    "df[text_col] = df[text_col].fillna(\"\")\n",
    "\n",
    "# (Opcional) Eliminar filas con todas las etiquetas NaN (no debería ser el caso)\n",
    "# df = df.dropna(subset=label_cols, how=\"all\").reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539d7fca",
   "metadata": {},
   "source": [
    "## 5. Limpieza básica del texto (regex)\n",
    "\n",
    "Creamos una función `clean_text` que:\n",
    "\n",
    "- Convierte a minúsculas.\n",
    "- Elimina URLs.\n",
    "- Elimina menciones (`@user`).\n",
    "- Sustituye hashtags (#hashtag) por la palabra sin `#`.\n",
    "- Elimina tags HTML.\n",
    "- Elimina caracteres no alfabéticos principales (dejamos letras y apóstrofes).\n",
    "- Normaliza espacios múltiples.\n",
    "\n",
    "Esta etapa reduce ruido antes de tokenizar y lematizar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c016477",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_PATTERN = re.compile(r\"http\\S+|www\\.\\S+\")\n",
    "MENTION_PATTERN = re.compile(r\"@\\w+\")\n",
    "HASHTAG_PATTERN = re.compile(r\"#(\\w+)\")\n",
    "HTML_TAG_PATTERN = re.compile(r\"<.*?>\")\n",
    "NON_LETTER_PATTERN = re.compile(r\"[^a-zA-Z' ]+\")\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Limpia texto crudo aplicando varias transformaciones basadas en regex.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "\n",
    "    # Minúsculas\n",
    "    text = text.lower()\n",
    "\n",
    "    # Quitar URLs\n",
    "    text = URL_PATTERN.sub(\" \", text)\n",
    "\n",
    "    # Quitar menciones @user\n",
    "    text = MENTION_PATTERN.sub(\" \", text)\n",
    "\n",
    "    # Sustituir hashtags por la palabra sin '#'\n",
    "    text = HASHTAG_PATTERN.sub(r\"\\1\", text)\n",
    "\n",
    "    # Quitar tags HTML\n",
    "    text = HTML_TAG_PATTERN.sub(\" \", text)\n",
    "\n",
    "    # Eliminar caracteres no alfabéticos principales (dejamos letras y apostrofes)\n",
    "    text = NON_LETTER_PATTERN.sub(\" \", text)\n",
    "\n",
    "    # Normalizar espacios\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e564c31",
   "metadata": {},
   "source": [
    "## 6. Aplicar la limpieza al texto\n",
    "\n",
    "Aplicamos `clean_text` sobre la columna `Text` y creamos la columna `text_clean`.\n",
    "\n",
    "Mostramos algunos ejemplos antes/después para verificar que la limpieza es razonable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd617c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplos de limpieza de texto:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>You call yourself an anarchist but defend a co...</td>\n",
       "      <td>you call yourself an anarchist but defend a co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>My mother told me the same thing.  God Bless t...</td>\n",
       "      <td>my mother told me the same thing god bless thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>Love it I same the saem thing Go Peggy!  #stup...</td>\n",
       "      <td>love it i same the saem thing go peggy stupid ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>Next time they do that, line up some cars and ...</td>\n",
       "      <td>next time they do that line up some cars and s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>He was Robbing the Store and Being a Big Man ....</td>\n",
       "      <td>he was robbing the store and being a big man i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text  \\\n",
       "521  You call yourself an anarchist but defend a co...   \n",
       "737  My mother told me the same thing.  God Bless t...   \n",
       "740  Love it I same the saem thing Go Peggy!  #stup...   \n",
       "660  Next time they do that, line up some cars and ...   \n",
       "411  He was Robbing the Store and Being a Big Man ....   \n",
       "\n",
       "                                            text_clean  \n",
       "521  you call yourself an anarchist but defend a co...  \n",
       "737  my mother told me the same thing god bless thi...  \n",
       "740  love it i same the saem thing go peggy stupid ...  \n",
       "660  next time they do that line up some cars and s...  \n",
       "411  he was robbing the store and being a big man i...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text_clean\"] = df[text_col].apply(clean_text)\n",
    "\n",
    "print(\"Ejemplos de limpieza de texto:\")\n",
    "df[[text_col, \"text_clean\"]].sample(5, random_state=RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab696de",
   "metadata": {},
   "source": [
    "## 7. Tokenización, stopwords y lematización con spaCy\n",
    "\n",
    "En este paso:\n",
    "\n",
    "- Cargamos el modelo de spaCy en inglés (`en_core_web_sm`).\n",
    "- Definimos una función que:\n",
    "  - Tokeniza.\n",
    "  - Elimina stopwords, espacios y puntuación.\n",
    "  - Lematiza cada token.\n",
    "- Devolvemos un texto de salida con lemas concatenados, listo para\n",
    "  ser vectorizado en el notebook de modelado.\n",
    "\n",
    "> Si el modelo no está instalado, ejecuta en terminal:\n",
    "> `python -m spacy download en_core_web_sm`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0d99b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga del modelo de spaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Stopwords adicionales específicas del dominio (puedes ajustarlas tras el EDA)\n",
    "custom_stopwords = {\n",
    "    \"video\", \"youtube\", \"watch\", \"channel\",\n",
    "    # añade aquí términos poco informativos que hayas visto en el EDA\n",
    "}\n",
    "\n",
    "def lemmatize_and_remove_stopwords(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Tokeniza, lematiza y elimina stopwords/puntuación usando spaCy.\n",
    "    Devuelve un string con tokens lematizados, listo para vectorizar.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "\n",
    "    tokens = []\n",
    "    for token in doc:\n",
    "        if token.is_space or token.is_punct:\n",
    "            continue\n",
    "\n",
    "        lemma = token.lemma_.lower().strip()\n",
    "\n",
    "        # Stopwords de spaCy + stopwords personalizadas\n",
    "        if lemma in nlp.Defaults.stop_words or lemma in custom_stopwords:\n",
    "            continue\n",
    "\n",
    "        if not lemma:\n",
    "            continue\n",
    "\n",
    "        tokens.append(lemma)\n",
    "\n",
    "    return \" \".join(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d310c1",
   "metadata": {},
   "source": [
    "## 8. Generar la columna final `text_processed`\n",
    "\n",
    "Aplicamos la función de lematización a `text_clean` para obtener `text_processed`.\n",
    "\n",
    "Esta es la columna que usaremos en `03_Modeling.ipynb` para:\n",
    "\n",
    "- Vectorizar (TF-IDF, embeddings, etc.).\n",
    "- Entrenar los modelos de clasificación.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0f61901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplos de texto procesado:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>You call yourself an anarchist but defend a co...</td>\n",
       "      <td>you call yourself an anarchist but defend a co...</td>\n",
       "      <td>anarchist defend cop shoot unarmed civilian hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>My mother told me the same thing.  God Bless t...</td>\n",
       "      <td>my mother told me the same thing god bless thi...</td>\n",
       "      <td>mother tell thing god bless woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>Love it I same the saem thing Go Peggy!  #stup...</td>\n",
       "      <td>love it i same the saem thing go peggy stupid ...</td>\n",
       "      <td>love saem thing peggy stupid ya kill ya self q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>Next time they do that, line up some cars and ...</td>\n",
       "      <td>next time they do that line up some cars and s...</td>\n",
       "      <td>time line car start burnout smoke riot gas non...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>He was Robbing the Store and Being a Big Man ....</td>\n",
       "      <td>he was robbing the store and being a big man i...</td>\n",
       "      <td>rob store big man play fire burn police job</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text  \\\n",
       "521  You call yourself an anarchist but defend a co...   \n",
       "737  My mother told me the same thing.  God Bless t...   \n",
       "740  Love it I same the saem thing Go Peggy!  #stup...   \n",
       "660  Next time they do that, line up some cars and ...   \n",
       "411  He was Robbing the Store and Being a Big Man ....   \n",
       "\n",
       "                                            text_clean  \\\n",
       "521  you call yourself an anarchist but defend a co...   \n",
       "737  my mother told me the same thing god bless thi...   \n",
       "740  love it i same the saem thing go peggy stupid ...   \n",
       "660  next time they do that line up some cars and s...   \n",
       "411  he was robbing the store and being a big man i...   \n",
       "\n",
       "                                        text_processed  \n",
       "521  anarchist defend cop shoot unarmed civilian hi...  \n",
       "737                  mother tell thing god bless woman  \n",
       "740  love saem thing peggy stupid ya kill ya self q...  \n",
       "660  time line car start burnout smoke riot gas non...  \n",
       "411        rob store big man play fire burn police job  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text_processed\"] = df[\"text_clean\"].apply(lemmatize_and_remove_stopwords)\n",
    "\n",
    "print(\"Ejemplos de texto procesado:\")\n",
    "df[[text_col, \"text_clean\", \"text_processed\"]].sample(5, random_state=RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36afe662",
   "metadata": {},
   "source": [
    "## 9. Comprobación rápida de etiquetas y texto procesado\n",
    "\n",
    "Antes de guardar el CSV preprocesado, revisamos:\n",
    "\n",
    "- Distribución de la etiqueta agregada `IsAnyToxic`.\n",
    "- Ejemplos de texto procesado por clase (tóxico / no tóxico).\n",
    "\n",
    "Esto sirve como sanity check del preprocesamiento.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
